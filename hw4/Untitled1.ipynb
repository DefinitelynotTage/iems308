{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IEMS308 HW4\n",
    "## Author: Taige Hong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from collections import Counter\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from elasticsearch_dsl import Search, query\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = \"Which company went bankrupt in?\"\n",
    "p2 = \"What affects GDP?\"\n",
    "p3 = \"What percentage of drop or increase is associated with?\"\n",
    "p4 = \"Who is the CEO of?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP = set(stopwords.words(\"english\"))\n",
    "def remove_stop(t):\n",
    "    temp = []\n",
    "    for i in t.split():\n",
    "        if i.lower() not in STOP:\n",
    "            temp.append(i)\n",
    "    return \" \".join(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use cosine similarity to determine which question is asked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(q, sq):\n",
    "    q_nsw = remove_stop(q)\n",
    "    sq_nsw = remove_stop(sq)\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    q_stemmed = \" \".join([stemmer.stem(word) for word in q_nsw.split()])\n",
    "    sq_stemmed = \" \".join([stemmer.stem(word) for word in sq_nsw.split()])\n",
    "    q_all = re.findall(r'\\w+', q_stemmed.lower())\n",
    "    sq_all = re.findall(r'\\w+', sq_stemmed.lower())\n",
    "    commonwords = set(Counter(q_all).keys()) & set(Counter(sq_all).keys())\n",
    "    cosine_likelihood = sum(Counter(q_all)[word] * Counter(sq_all)[word] for word in commonwords) / ((math.sqrt(sum(Counter(q_all)[x] ** 2 for x in Counter(q_all).keys()))) * (math.sqrt(sum(Counter(sq_all)[x] ** 2 for x in Counter(sq_all).keys()))))\n",
    "    return cosine_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the files and dump them into Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(730, [])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading files\n",
    "alltext = []\n",
    "\n",
    "for file in os.listdir('2013/'):\n",
    "    alltext.append(open(os.path.join('2013', file), 'rb').read().decode('ISO-8859-1'))\n",
    "for file in os.listdir('2014/'):\n",
    "    alltext.append(open(os.path.join('2014', file), 'rb').read().decode('ISO-8859-1'))\n",
    "    \n",
    "#Setup Elasticsearch, we have to make sure elasticsearch is running at localhost:9200\n",
    "es = Elasticsearch()\n",
    "\n",
    "datestart = datetime(2013,1,1)\n",
    "docs = []\n",
    "for i in range(len(alltext)):\n",
    "    doc = {\n",
    "        '_index': \"article\",\n",
    "        '_type': \"article\",\n",
    "        '_id': i,\n",
    "        'content': alltext[i]\n",
    "    }\n",
    "    docs.append(doc)\n",
    "helpers.bulk(es, docs)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the three questions, we are using the same logistics to process the questions-- find out the keywords and extract all sentences with those keywords. Then we use Regex expression to filter out the candidate words and use Counter to find the one that appears most frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer1(q):\n",
    "    monthdict = {'January':1, 'February':2, 'March':3, 'April':4,\n",
    "                'May':5, 'June':6, 'July':7, 'August':8,\n",
    "                'September':9 , 'October':10 , 'November':11 , 'December':12}\n",
    "    tokens = nltk.word_tokenize(q)\n",
    "    month = list(filter(lambda x: x in tokens, monthdict))[0]\n",
    "    years = re.findall(r'\\d{4}', q)\n",
    "    if (years):\n",
    "        year = years[0]\n",
    "    else:\n",
    "        return \"Sorry, cannot find year\"\n",
    "    \n",
    "    qc = query.Q(\"query_string\", query = \"bankrupt bankruptcy liqudate declare\")\n",
    "    qm = query.Q(\"query_string\", query =  month)\n",
    "    qy = query.Q(\"query_string\", query =  year)\n",
    "    \n",
    "    q1 =  qc + qm + qy\n",
    "    search = Search(using = es, index = \"article\")\n",
    "    search = search.query(q1)\n",
    "    search = search[:200]\n",
    "    result = search.execute()\n",
    "    sents = []\n",
    "    for i in range(len(result.hits)):\n",
    "        sent = nltk.tokenize.sent_tokenize(result.hits[i].content)\n",
    "        sent = filter(lambda x: ((\"bankrupt\" in x.lower()) & (year in x)), sent)\n",
    "        sents.extend(sent)\n",
    "    names = [re.findall(r\" (?:[A-Z]+[A-Za-z0-9']+ ?)+\", sent) for sent in sents]\n",
    "    namelist = []\n",
    "    STOP1 = [\"chapter\", \"bankrupt\", \"bankruptcy\", \"liquidated\"]\n",
    "    for i in range(len(names)):\n",
    "        name = map(lambda x: x.strip().lstrip(), names[i])\n",
    "        validword = filter(lambda x: ((x.lower() not in STOP) & (x.lower() not in STOP1) & (x not in monthdict)) , name)\n",
    "        namelist.extend(validword)\n",
    "    \n",
    "    word_count = Counter(namelist)\n",
    "    return word_count.most_common(1)[0][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['however', 'stocks', 'fund', 'around', 'banks', 'three',\n",
       "        'likely', 'funds', 'think', 'global', 'recent', 'higher', 'next',\n",
       "        'way', 'expected', 'says', 'today', 'low', 'day', 'federal',\n",
       "        'going', 'risk', 'big', 'quarter', 'tax', '2013', 'debt',\n",
       "        'interest', 'sales', 'still', '2014', 'make', 'companies',\n",
       "        'capital', 'see', 'report', 'amp', 'month', 'back', 'week',\n",
       "        'term', 'well', 'inflation', 'price', '10', 'policy', 'get',\n",
       "        'investment', 'many', 'long', '000', 'high', 'much', 'according',\n",
       "        'fed', 'china', 'oil', 'rates', 'money', 'reuters', 'stock',\n",
       "        'investors', 'data', 'two', 'world', 'even', 'economy',\n",
       "        'markets', 'government', 'prices', 'first', 'business', 'rate',\n",
       "        'million', 'us', 'bank', 'economic', 'like', 'since', 'may',\n",
       "        'financial', 'company', 'could', 'people', 'free', 'billion',\n",
       "        'last', 'years', 'time', 'growth', 'percent', 'also',\n",
       "        'free appdownload', 'appdownload', 'new', 'one', 'would',\n",
       "        'market', 'year', 'said']], dtype='<U57')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    q2 = query.Q(\"query_string\", query = \"GDP\") + query.Q(\"query_string\", query = \"affect effect\")\n",
    "    search = Search(using = es, index = \"article\")\n",
    "    search = search.query(q2)\n",
    "    search = search[:50]\n",
    "    result = search.execute()\n",
    "    articles = [hit.content for hit in result.hits]\n",
    "    algo = TfidfVectorizer(ngram_range = (1,2), stop_words = STOP)\n",
    "    applied = algo.fit_transform(articles)\n",
    "    freqs = np.sum(applied, axis = 0)\n",
    "    index = np.argsort(freqs)[:,-100:]\n",
    "    words = np.array(algo.get_feature_names())[index]\n",
    "    words\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the best way to find out the factors affecting GDP is to conclude from this list of words as it is more efficient than expanding the stop words set. I also tried to filter out only \"NN\" and \"NNS\" but it turns out not to be so effective. Thus, the question to \"What affects GDP?\" is manually answered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer2():\n",
    "    return ['spending', \"stock\", \"tax\", \"debt\", \"interest\", \"inflation\", \"policy\", \"investor\", \"market\", \"price\", \"growth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer3(q):\n",
    "    keyword = list(filter(lambda x: x in q.lower(), answer2()))\n",
    "    if (keyword):\n",
    "        key = keyword[0]\n",
    "    else:\n",
    "        return \"Sorry, I don't know about that.\"\n",
    "    q3 = query.Q(\"query_string\", query = \"GDP\") + query.Q(\"query_string\", query = key)\n",
    "    search = Search(using = es, index = \"article\")\n",
    "    search = search.query(q3)\n",
    "    search = search[:50]\n",
    "    result = search.execute()\n",
    "    sents = []\n",
    "    for i in range(len(result.hits)):\n",
    "        sent = nltk.tokenize.sent_tokenize(result.hits[i].content)\n",
    "        sent = filter(lambda x: ((\"GDP\" in x) & (key in x)), sent)\n",
    "        sents.extend(sent)\n",
    "    pattern = r'(([0-9]+)|(one)|(two)|(three)|(four)|(five)|(six)|(seven)|(eight)|(nine)|(ten))[.[0-9]*]?(%| percentage point| percent)+s?'\n",
    "    names = [re.findall(pattern, sent) for sent in sents]\n",
    "    namelist = []\n",
    "    for i in range(len(names)):\n",
    "        name = map(lambda x: \"\".join(x[1:]), names[i])\n",
    "        namelist.extend(name)\n",
    "    word_count = Counter(namelist)\n",
    "    return word_count.most_common(1)[0][0]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer4(q):\n",
    "    comname = re.findall(r\" (?:[A-Z]+[A-Za-z0-9']+ ?)+\", q)[-1].lstrip()\n",
    "    q3 = query.Q(\"query_string\", query = \"CEO\") + query.Q(\"query_string\", query = comname)\n",
    "    search = Search(using = es, index = \"article\")\n",
    "    search = search.query(q3)\n",
    "    search = search[:50]\n",
    "    result = search.execute()\n",
    "    sents = []\n",
    "    for i in range(len(result.hits)):\n",
    "        sent = nltk.tokenize.sent_tokenize(result.hits[i].content)\n",
    "        sent = filter(lambda x: ((\"CEO\" in x) & (comname in x)), sent)\n",
    "        sents.extend(sent)\n",
    "    names = [re.findall(r\" (?:[A-Z]+[A-Za-z0-9']+ ?)+\", sent) for sent in sents]\n",
    "    namelist = []\n",
    "    for i in range(len(names)):\n",
    "        name = map(lambda x: x.strip().lstrip() ,names[i])\n",
    "        name = filter(lambda x: ((x not in STOP) & (x != \"CEO\") & (x != comname)), name)\n",
    "        namelist.extend(name)\n",
    "    word_count = Counter(namelist)\n",
    "    if word_count:\n",
    "        common = word_count.most_common(1)[0][0] \n",
    "    else:\n",
    "        return \"Sorry, I can't find the CEO of this company.\"\n",
    "    common_token = nltk.tokenize.word_tokenize(common)\n",
    "    return \" \".join(filter(lambda x: ((x != \"CEO\") & (x != comname)), common_token))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I set the cutoff value of cosine_similarity to 0.42 by trials and errors. This prevent the system from answering nonsen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(q):\n",
    "    vector = []\n",
    "    s1 = similarity(q, p1)\n",
    "    s2 = similarity(q, p2)\n",
    "    s3 = similarity(q, p3)\n",
    "    s4 = similarity(q, p4)\n",
    "    maxvalue = max(s1, s2, s3, s4)\n",
    "    if (maxvalue < 0.42):\n",
    "        return \"I can't answer this question.\"\n",
    "    elif (maxvalue == s1):\n",
    "        return answer1(q)\n",
    "    elif (maxvalue == s2):\n",
    "        return answer2()\n",
    "    elif (maxvalue == s3):\n",
    "        return answer3(q)\n",
    "    elif (maxvalue == s4):\n",
    "        return answer4(q)\n",
    "    else:\n",
    "        return \"Something went wrong, you shouldn't be getting this msg.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lehman Brothers'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"Which company went bankrupt in September 2008?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chrysler'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"Which company declared bankrupt in October 2009?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MF Global'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"Which company went bankrupt in February 2013?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spending',\n",
       " 'stock',\n",
       " 'tax',\n",
       " 'debt',\n",
       " 'interest',\n",
       " 'inflation',\n",
       " 'policy',\n",
       " 'investor',\n",
       " 'market',\n",
       " 'price',\n",
       " 'growth']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"What affects GDP?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1%'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"By what percentage is GDP associated with tax?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3%'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"What percentage of increase or drop is related to inflation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4%'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"By how much is GDP associated with the increase and drop of spending?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jeff Bezos'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"Who is the CEO of Amazon?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Elon Musk'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"Who is the CEO of Tesla?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mark Zuckerberg'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"Who is the CEO of Facebook?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
